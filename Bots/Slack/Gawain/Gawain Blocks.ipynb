{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import unzip_requirements\n",
    "except ImportError:\n",
    "  pass\n",
    "\n",
    "import pandas as pd\n",
    "import distance\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import psycopg2\n",
    "from geopy.geocoders import Nominatim\n",
    "import boto3\n",
    "from geopy.distance import geodesic\n",
    "import analytics\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics.write_key = os.environ.get('SEGMENT_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "etype = []\n",
    "etext = []\n",
    "edate = []\n",
    "jid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server connected\n",
      "database connected\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with SSHTunnelForwarder(\n",
    "        (os.environ.get('JOUST_IP'), 22),\n",
    "        ssh_private_key=\"~/.ssh/id_rsa\",\n",
    "        ssh_username=\"ubuntu\",\n",
    "        remote_bind_address=(os.environ.get('JOUST_ADDRESS'), 5432)) as server:\n",
    "\n",
    "        server.start()\n",
    "        print(\"server connected\")\n",
    "\n",
    "        params = {\n",
    "            \"database\": \"joust_production\",\n",
    "            \"user\": \"sid\",\n",
    "            \"password\": os.environ.get('JOUST_PASS'),\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": server.local_bind_port\n",
    "        }\n",
    "\n",
    "        conn = psycopg2.connect(**params)\n",
    "        curs = conn.cursor()\n",
    "        print(\"database connected\")\n",
    "\n",
    "        plaid = \"select account_holders.id, first_name,last_name, addresses.line_1,addresses.line_2,addresses.city,addresses.state,addresses.zip,mobile_phone,email,plaid_identities.updated_at,plaid_identities.raw_response->>'owners', businesses.\\\"name\\\" from account_holders right join external_bank_accounts on account_holders.id = external_bank_accounts.account_holder_id right join plaid_identities on external_bank_accounts.id = plaid_identities.plaid_identifiable_id inner join addresses on account_holders.id = addresses.addressable_id inner join businesses on account_holders.id = businesses.account_holder_id and plaid_identifiable_type='ExternalBankAccount'\"\n",
    "        invoices = \"SELECT account_holders.id,payment_requests.payment_type,payment_requests.transaction_code,payment_requests.status,first_name,last_name,account_holders.created_at,payment_requests.paid_date,payment_requests.amount,payment_requests.created_at as created_at2, payment_requests.business_entity_payer_id from account_holders inner join payment_requests on account_holders.id = payment_requests.account_holder_id\"\n",
    "        status = \"SELECT core_pro_customers.account_holder_id as id, promo_codes.\\\"name\\\" as promo_codes from core_pro_customers left join account_holder_promo_codes on core_pro_customers.account_holder_id = account_holder_promo_codes.account_holder_id left join promo_codes on promo_codes.id = account_holder_promo_codes.promo_code_id\"\n",
    "        devices = \"select account_holders.id, first_name, last_name, devices.signature, devices.platform, devices.created_at from account_holders inner join account_holder_devices on account_holders.id = account_holder_devices.account_holder_id inner join devices on account_holder_devices.device_id = devices.id\"\n",
    "        trpay1 = \"select account_holders.id as userid, payment_requests.id, account_holders.first_name,account_holders.last_name,account_holders.email,account_holders.mobile_phone from payment_requests inner join account_holders on payment_requests.account_holder_id = account_holders.id inner join addresses on payment_requests.account_holder_id = addresses.addressable_id where addressable_type = 'AccountHolder'\"\n",
    "        trpay2 = \"select payment_requests.id, business_entity_payers.first_name, business_entity_payers.last_name, business_entity_payers.mobile_number, business_entity_payers.email, business_entities.\\\"name\\\", business_entities.phone_number, payment_requests.created_at from payment_requests inner join business_entity_payers on payment_requests.business_entity_payer_id = business_entity_payers.id left join business_entities on business_entity_payers.business_entity_id = business_entities.id inner join addresses on payment_requests.business_entity_payer_id = addresses.addressable_id where addressable_type = 'BusinessEntity'\"\n",
    "\n",
    "\n",
    "\n",
    "        plaid = pd.read_sql_query(plaid, conn)\n",
    "        req = pd.read_sql_query(invoices, conn)\n",
    "        phones = pd.read_sql_query(devices, conn)\n",
    "        stat = pd.read_sql_query(status, conn)\n",
    "        trpay1 = pd.read_sql_query(trpay1, conn)\n",
    "        trpay2 = pd.read_sql_query(trpay2, conn)\n",
    "\n",
    "        conn.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Connection Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trpay = trpay1.merge(trpay2, left_on='id', right_on='id')\n",
    "trpay = trpay.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaid = plaid.rename(columns={\"first_name\": \"First Name\", \"last_name\": \"Last Name\", \"?column?\": \"Raw Response\"})\n",
    "req = req.rename(columns={\"first_name\": \"First Name\", \"last_name\": \"Last Name\", \"status\": \"Status\", \"amount\": \"Amount (Payment Requests)\", \"created_at\": \"Created At\", \"created_at2\": \"Created At (Payment Requests)\", \"paid_date\": \"Accepted Date\"})\n",
    "stat = stat.rename(columns={\"first_name\": \"First Name\", \"last_name\": \"Last Name\"})\n",
    "phones = phones.rename(columns={\"Name\": \"Full Name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaid['updated_at'] =  pd.to_datetime(plaid['updated_at'])\n",
    "req['Created At'] =  pd.to_datetime(req['Created At'])\n",
    "req['Created At (Payment Requests)'] =  pd.to_datetime(req['Created At (Payment Requests)'])\n",
    "req['Accepted Date'] =  pd.to_datetime(req['Accepted Date'])\n",
    "phones['created_at'] =  pd.to_datetime(phones['created_at'])\n",
    "trpay['created_at'] =  pd.to_datetime(trpay['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "req['Full Name'] = req['First Name'].astype(str).values + ' ' + req['Last Name'].astype(str).values\n",
    "req = req.drop(['First Name','Last Name'], axis=1)\n",
    "phones['Full Name'] = phones['first_name'].astype(str).values + ' ' + phones['last_name'].astype(str).values\n",
    "phones = phones.drop(['first_name','last_name'], axis=1)\n",
    "trpay['Full Name'] = trpay['first_name_y'].astype(str).values + ' ' + trpay['last_name_y'].astype(str).values\n",
    "trpay = trpay.drop(['first_name_y','last_name_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaid['now'] = datetime.utcnow()\n",
    "req['now'] = datetime.utcnow()\n",
    "phones['now'] = datetime.utcnow()\n",
    "trpay['now'] = datetime.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaid['timediff'] = (plaid['now'] - plaid['updated_at']).dt.total_seconds() / 3600\n",
    "req['timediff'] = (req['now'] - req['Created At (Payment Requests)']).dt.total_seconds() / 3600\n",
    "phones['timediff'] = (phones['now'] - phones['created_at']).dt.total_seconds() / 3600\n",
    "trpay['timediff'] = (trpay['now'] - trpay['created_at']).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaid = plaid.fillna('')\n",
    "plaid['location'] = plaid[\"line_1\"].astype(str) + plaid[\"line_2\"].astype(str) + ' ' + plaid[\"city\"].astype(str) + ', ' + plaid[\"zip\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "newplaid = plaid[plaid['timediff'] < 10000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fids = []\n",
    "ffullname = []\n",
    "fnamecheck = []\n",
    "lnamecheck = []\n",
    "fullnamecheck = []\n",
    "biznamecheck = []\n",
    "nnamedist = []\n",
    "biznamedist = []\n",
    "minnamedist = []\n",
    "statematch = []\n",
    "zipmatch = []\n",
    "emailmatch = []\n",
    "phonematch = []\n",
    "nameoncards = []\n",
    "plaiddate = []\n",
    "for npp in newplaid.values:\n",
    "    pldate = npp[-6]\n",
    "    plaiddate.append(pldate)\n",
    "    plid = npp[0]\n",
    "    plfname = npp[1].lower()\n",
    "    pllname = npp[2].lower()\n",
    "    ffullname.append(npp[1] + ' ' + npp[2])\n",
    "    plstate = npp[6].lower()\n",
    "    plzip = npp[7]\n",
    "    plphone = npp[8]\n",
    "    plemail = npp[9].lower()\n",
    "    plcomp = npp[12].lower()\n",
    "    pllocation = npp[-1]\n",
    "    card = json.loads(npp[11])[0]\n",
    "    cname = ''\n",
    "    if (len(card['names']) > 0):\n",
    "        cname = card['names'][0].lower()\n",
    "    nameoncards.append(cname)\n",
    "    cemail = ''\n",
    "    if (len(card['emails']) > 0):\n",
    "        cemail = card['emails'][0]['data'].lower()\n",
    "    cstate = ''\n",
    "    czip = ''\n",
    "    clocation = ''\n",
    "    if (len(card['addresses']) > 0):\n",
    "        caddr = card['addresses'][0]['data']\n",
    "        cstate = caddr['region'].lower()\n",
    "        czip = caddr['postal_code']\n",
    "        clocation = caddr['street'] + ' ' + caddr['city'] + ', ' + caddr['region'] + ' ' + caddr['postal_code']\n",
    "    cphone = ''\n",
    "    if (len(card['phone_numbers']) > 0):\n",
    "        cphone = card['phone_numbers'][0]['data']\n",
    "    fids.append(plid)\n",
    "    fnamecheck.append(plfname in cname)\n",
    "    lnamecheck.append(pllname in cname)\n",
    "    biznamecheck.append((plcomp in cname) | (cname in plcomp))\n",
    "    fullnamecheck.append((plfname in cname) & (pllname in cname))\n",
    "    nnamedist.append(distance.levenshtein(plfname + ' ' + pllname,cname))\n",
    "    biznamedist.append(distance.levenshtein(plcomp,cname))\n",
    "    minnamedist.append(min(distance.levenshtein(plcomp,cname), distance.levenshtein(plfname + ' ' + pllname,cname)))\n",
    "    statematch.append(plstate in cstate)\n",
    "    zipmatch.append(plzip in czip)\n",
    "    emailmatch.append(plemail in cemail)\n",
    "    phonematch.append(plphone in cphone)\n",
    "\n",
    "plaidex = pd.DataFrame(fids, columns=['id'])\n",
    "plaidex['fnamecheck'] = fnamecheck\n",
    "plaidex['lnamecheck'] = lnamecheck\n",
    "plaidex['biznamecheck'] = biznamecheck\n",
    "plaidex['nnamedist'] = nnamedist\n",
    "plaidex['biznamedist'] = biznamedist\n",
    "plaidex['minnamedist'] = minnamedist\n",
    "plaidex['statematch'] = statematch\n",
    "plaidex['zipmatch'] = zipmatch\n",
    "plaidex['emailmatch'] = emailmatch\n",
    "plaidex['phonematch'] = phonematch\n",
    "plaidex = plaidex*1\n",
    "plaidex['fullname'] = ffullname\n",
    "plaidex['cardname'] = nameoncards\n",
    "plaidex['date'] = plaiddate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pk in plaidex.values:\n",
    "    if (((pk[1] == 0) | (pk[2] == 0)) & (pk[4] >= 3)):\n",
    "        pmssg = (pk[-3] + ' falsely linked their account to ' + pk[-2])\n",
    "        pid = (pk[0])\n",
    "        pdate = (pk[-1])\n",
    "        \n",
    "        etype.append('false linked account')\n",
    "        etext.append(pmssg)\n",
    "        edate.append(pdate)\n",
    "        jid.append(pid)\n",
    "        #analytics.identify(segment, {\n",
    "        #    'joust_id': pid,\n",
    "        #    'message': pmssg,\n",
    "        #    'type': 'false linked account',\n",
    "        #    'created_at': pdate\n",
    "        #})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add segment ids (ids copy -> ids segid replace from new table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "req['timediff2'] = (req['now'] - req['Accepted Date']).dt.total_seconds() / 3600\n",
    "req = req.sort_values('timediff2', ascending=True)\n",
    "stat = stat.groupby('id')['promo_codes'].apply(list).to_frame()\n",
    "stat = stat[['promo_codes']]\n",
    "req2 = req.merge(stat, left_on='id', right_on='id')\n",
    "req2 = req2.sort_values('timediff2', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "req3 = req2[req2['timediff2'] < 100]\n",
    "for k in req3.values:\n",
    "    ptype = k[1]\n",
    "    if (ptype < 1):\n",
    "        ptnam = 'ProPay'\n",
    "    else:\n",
    "        ptnam = 'ACH'\n",
    "    idnum = k[0]\n",
    "    pval = k[6]\n",
    "    fnam = k[9]\n",
    "    promo = k[13]\n",
    "    if promo is None:\n",
    "        paymssg = (fnam + ' (id: ' + str(idnum) + ') just got their invoice of $' + str(pval) + ' paid via ' + ptnam )\n",
    "        #print(paymssg)\n",
    "    else:\n",
    "        paymssg = (str(fnam) + ' (id: ' + str(idnum) + ') with promo code ' + str(promo) + ' just got their invoice of $' + str(pval) + ' paid via ' + str(ptnam) )\n",
    "        #print(paymssg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones2 = phones[phones['timediff'] < 100]\n",
    "sigs = phones2['signature'].values\n",
    "undev = []\n",
    "for sig in sigs:\n",
    "    undev.append(len(phones[phones['signature'] == sig]['Full Name'].unique()))\n",
    "phones2['unique'] = undev\n",
    "phones2 = phones2[phones2['unique'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigs = phones2['signature'].unique()\n",
    "ucounts = []\n",
    "unames = []\n",
    "uids = []\n",
    "for sig in sigs:\n",
    "    phones3 = phones2[phones2['signature'] == sig]\n",
    "    ucounts.append(len(phones3))\n",
    "    unames.append(phones3['Full Name'].unique())\n",
    "    uids.append(phones3['id'].unique())\n",
    "phonefin = pd.DataFrame(sigs, columns=['signature'])\n",
    "phonefin['count'] = ucounts\n",
    "phonefin['names'] = unames\n",
    "phonefin['ids'] = uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mphone2 = ''\n",
    "for k in range(len(sigs)):\n",
    "    mphone2 = mphone2 + 'Device ' + sigs[k] + ' is used by ' + str(unames[k]) + ' (id: ' + str(uids[k]) + '). \\n'\n",
    "mphone1 = 'There were ' + str(len(phonefin)) + ' accounts with devices that have been seen before.'\n",
    "if (len(phonefin) > 0):\n",
    "    print(mphone1)\n",
    "    print(mphone2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "req4 = req.sort_values('timediff', ascending=True)\n",
    "req4 = req4[req4['timediff'] < 24]\n",
    "dtids = req4[req4['timediff'] < 1]['id'].unique()\n",
    "for num in dtids:\n",
    "    req5 = req4[req4['id'] == num]\n",
    "    if (len(req5) > len(req5['business_entity_payer_id'].unique())):\n",
    "        print(req5.values[0])\n",
    "        invm = req5.values[0][9] + ' ( id:'+ str(req5.values[0][0]) +' )' +' has sent multiple invoices to the same person in the last 24 hrs.'\n",
    "        print(invm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trpay2 = trpay[trpay['timediff'] < 2400000]\n",
    "tpids = []\n",
    "tpfullnam = []\n",
    "fmat = []\n",
    "lmat = []\n",
    "mailmat = []\n",
    "phonemat = []\n",
    "tpdates = []\n",
    "for tp in trpay2.values:\n",
    "    tpdate = tp[-4]\n",
    "    tpdates.append(tpdate)\n",
    "    tpid = tp[0]\n",
    "    tpids.append(tpid)\n",
    "    tpfnam = tp[2].lower()\n",
    "    tplnam = tp[3].lower()\n",
    "    tpfullnam.append(tp[2] + ' ' + tp[3])\n",
    "    tpemail = tp[4].lower()\n",
    "    tpphone = tp[5]\n",
    "    cpemail = tp[7].lower()\n",
    "    cpphone = tp[6]\n",
    "    cpfnam = tp[-3].lower()\n",
    "    fmat.append(tpfnam in cpfnam)\n",
    "    lmat.append(tplnam in cpfnam)\n",
    "    mailmat.append(tpemail in cpemail)\n",
    "    phonemat.append(tpphone in cpphone)\n",
    "selfinv = pd.DataFrame(tpids, columns=['id'])\n",
    "selfinv['name'] = tpfullnam\n",
    "selfinv['fmat'] = fmat\n",
    "selfinv['lmat'] = lmat\n",
    "selfinv['mailmat'] = mailmat\n",
    "selfinv['phonemat'] = phonemat\n",
    "selfinv = selfinv*1\n",
    "selfinv['date'] = tpdates\n",
    "selfinv['fraud'] = selfinv['fmat'] + selfinv['lmat'] + selfinv['mailmat'] + selfinv['phonemat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for si in selfinv[selfinv['fraud'] > 0].values:\n",
    "    dupes = 'same '\n",
    "    if (si[2] > 0):\n",
    "        dupes = dupes + 'first name, '\n",
    "    if (si[3] > 0):\n",
    "        dupes = dupes + 'last name, '\n",
    "    if (si[4] > 0):\n",
    "        dupes = dupes + 'email, '\n",
    "    if (si[5] > 0):\n",
    "        dupes = dupes + 'phone, '\n",
    "    smssg = (si[1] + ' (id:' + str(si[0]) + ') has sent an invoice to themself. (' + dupes[0:-2] + ')')\n",
    "    sid = (si[0])\n",
    "    sdate = (si[-2])\n",
    "    etype.append('self invoice')\n",
    "    etext.append(smssg)\n",
    "    edate.append(sdate)\n",
    "    jid.append(sid)\n",
    "    #analytics.identify(segment, {\n",
    "    #    'joust_id': sid,\n",
    "    #    'message': smssg,\n",
    "    #    'type': 'self invoice',\n",
    "    #    'created_at': sdate\n",
    "    #})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(jid, columns=['Joust ID'])\n",
    "final['Event Type'] = etype\n",
    "final['Event Message'] = etext\n",
    "final['Event Date'] = edate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
