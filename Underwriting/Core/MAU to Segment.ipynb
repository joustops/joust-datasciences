{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import distance\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import psycopg2\n",
    "import analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics.write_key = os.environ.get('SEGMENT_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with SSHTunnelForwarder(\n",
    "        (os.environ.get('JOUST_IP'), 22),\n",
    "        ssh_private_key=\"~/.ssh/id_rsa\",\n",
    "        ssh_username=\"ubuntu\",\n",
    "        remote_bind_address=(os.environ.get('JOUST_ADDRESS'), 5432)) as server:\n",
    "\n",
    "        server.start()\n",
    "        print(\"server connected\")\n",
    "\n",
    "        params = {\n",
    "            \"database\": \"joust_production\",\n",
    "            \"user\": \"sid\",\n",
    "            \"password\": os.environ.get('JOUST_PASS'),\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": server.local_bind_port\n",
    "        }\n",
    "\n",
    "        conn = psycopg2.connect(**params)\n",
    "        curs = conn.cursor()\n",
    "        print(\"database connected\")\n",
    "\n",
    "        #curs.execute(\"select * from public.account_holders\")\n",
    "        transfers = \"select account_holders.id, first_name, last_name, amount, transfers.created_at as \\\"created_at.1\\\", core_pro_customers.customer_id as q2_core_pro_customer_id, from_account_id, transfers.customer_id, to_account_id from account_holders inner join transfers on account_holders.id = transfers.account_holder_id left join core_pro_customers on core_pro_customers.account_holder_id = account_holders.id\"\n",
    "        invoices = \"select account_holders.id, first_name, last_name, payment_requests.status, amount, account_holders.created_at, payment_requests.created_at as \\\"created_at.1\\\", accepted_date, core_pro_customers.customer_id as q2_core_pro_customer_id, payarmour_service, payment_type from account_holders inner join payment_requests on account_holders.id = payment_requests.account_holder_id left join core_pro_customers on core_pro_customers.account_holder_id = account_holders.id\"\n",
    "        total = \"select account_holders.id, account_holders.segment_intercom_id, first_name, last_name, occupations.\\\"name\\\" as occupation, industries.\\\"name\\\" as industry, marketing.value as legacy_business_url, type_of_work, locations.country, account_holders.created_at, sign_in_count, ssn, email, mobile_phone, date_of_birth, expected_yearly_income_id, core_pro_customers.customer_id as q2_core_pro_customer_id, payarmour_service from account_holders left join core_pro_customers on core_pro_customers.account_holder_id = account_holders.id left join locations on account_holders.id = locations.locatable_id left join occupations on account_holders.occupation_id = occupations.id left join industries on occupations.industry_id = industries.id left join businesses on businesses.account_holder_id = account_holders.id left join marketing on marketing.business_id = businesses.id and marketing.source = 2\"\n",
    "        plaid = \"select account_holders.id, first_name,last_name,plaid_identities.updated_at,plaid_identities.raw_response->>'owners' from account_holders inner join external_bank_accounts on account_holders.id = external_bank_accounts.account_holder_id inner join plaid_identities on external_bank_accounts.id = plaid_identities.plaid_identifiable_id and plaid_identifiable_type='ExternalBankAccount'\"\n",
    "        alloy = \"SELECT account_holders.first_name, account_holders.last_name, account_holders.id, alloy_results.alloy_score as alloy_id FROM account_holders INNER JOIN alloy_results ON alloy_results.resultable_id = account_holders.id AND alloy_results.resultable_type = 'AccountHolder'\"\n",
    "        bank = \"select account_holders.id, first_name,last_name,bank_accounts.q2_account_id,bank_accounts.is_primary,bank_accounts.available_balance from account_holders inner join bank_accounts on bank_accounts.account_holder_id = account_holders.id\"\n",
    "        devices = \"select account_holders.id, first_name, last_name, devices.signature, devices.platform, devices.created_at  from account_holders inner join account_holder_devices on account_holders.id = account_holder_devices.account_holder_id inner join devices on account_holder_devices.device_id = devices.id\"\n",
    "        stat = \"select account_holders.id, account_holders.created_at, account_holders.archived, account_activations.status, account_holders.email, first_name, last_name, verification_status as q2_core_pro_verification_status from account_holders left join core_pro_customers on account_holders.id = core_pro_customers.account_holder_id left join account_activations on account_holders.id = account_activations.account_holder_id\"\n",
    "        events = \"SELECT events.payload -> 'payloadTypeId' AS id, events.payload -> 'data' -> 0 -> 0 -> 'returnCode' AS returncode, events.payload -> 'data' -> 0 -> 0 -> 'type' AS type, events.payload -> 'data' -> 0 -> 0 -> 'amount' AS amount, events.payload -> 'data' -> 0 -> 0 -> 'customerId' AS customerId, events.payload -> 'data' -> 0 -> 0 -> 'createdDate' AS createdDate FROM \\\"events\\\"\"\n",
    "\n",
    "        #result = curs.fetchall()\n",
    "        tra = pd.read_sql_query(transfers, conn)\n",
    "        req = pd.read_sql_query(invoices, conn)\n",
    "        ids = pd.read_sql_query(total, conn)\n",
    "        ids.drop_duplicates(subset =\"id\", inplace = True)\n",
    "        plaid = pd.read_sql_query(plaid, conn)\n",
    "        bank = pd.read_sql_query(bank, conn)\n",
    "        cells = pd.read_sql_query(devices, conn)\n",
    "        rte = pd.read_sql_query(events, conn)\n",
    "        status = pd.read_sql_query(stat, conn)\n",
    "\n",
    "        conn.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Connection Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    params = {\n",
    "        \"database\": \"martechdb\",\n",
    "        \"user\": \"sid\",\n",
    "        \"password\": os.environ.get('MARTECH_PASS'),\n",
    "        \"host\": os.environ.get('MARTECH_ADDRESS'),\n",
    "        \"port\": 5439\n",
    "    }\n",
    "\n",
    "    conn = psycopg2.connect(**params)\n",
    "    curs = conn.cursor()\n",
    "    print(\"database connected\")\n",
    "    \n",
    "    negative = \"select * from ruby.negative_balance_alert\"\n",
    "\n",
    "    negj = pd.read_sql_query(negative, conn)\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Connection Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## As data gets big, do the query to isolate new users and new infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ids.rename(columns={\"first_name\": \"First Name\", \"last_name\": \"Last Name\", \"type_of_work\": \"Type Of Work\", \"created_at\": \"Created At\", \"legacy_business_url\": \"business_url\", \"sign_in_count\": \"Sign In Count\"})\n",
    "req = req.rename(columns={\"first_name\": \"First Name\", \"last_name\": \"Last Name\", \"status\": \"Status\", \"amount\": \"Amount (Payment Requests)\", \"created_at\": \"Created At\", \"created_at.1\": \"Created At (Payment Requests)\", \"accepted_date\": \"Accepted Date\", \"q2_core_pro_customer_id\": \"Q2 Core Pro Customer Id\"})\n",
    "plaid = plaid.rename(columns={\"first_name\": \"First Name\", \"last_name\": \"Last Name\", \"?column?\": \"Raw Response\"})\n",
    "tra = tra.rename(columns={\"first_name\": \"First Name\", \"last_name\": \"Last Name\", \"amount\": \"Amount\", \"created_at.1\": \"Created At (Transfers)\", \"q2_core_pro_customer_id\": \"Q2 Core Pro Customer Id\"})\n",
    "bank = bank.rename(columns={\"first_name\": \"First Name\", \"last_name\": \"Last Name\"})\n",
    "negj = negj.rename(columns={\"name\": \"Full Name\"})\n",
    "cells = cells.rename(columns={\"first_name\": \"First Name\", \"last_name\": \"Last Name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ids[['id','segment_intercom_id','First Name','Last Name','ssn','email','mobile_phone','date_of_birth','business_url','occupation','industry','country','expected_yearly_income_id','q2_core_pro_customer_id','Type Of Work','Created At','payarmour_service','Sign In Count']]\n",
    "req = req[['id','First Name','Last Name','Status','Amount (Payment Requests)','Created At','Created At (Payment Requests)','Accepted Date','Q2 Core Pro Customer Id','payarmour_service','payment_type']]\n",
    "tra = tra[['id','First Name','Last Name','Amount','Created At (Transfers)','Q2 Core Pro Customer Id','from_account_id','customer_id','to_account_id']]\n",
    "negj = negj[['Full Name','balance','user_id','effective_date','type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids['Created At'] = pd.to_datetime(ids['Created At'])\n",
    "req['Created At'] = pd.to_datetime(req['Created At'])\n",
    "req['Created At (Payment Requests)'] = pd.to_datetime(req['Created At (Payment Requests)'])\n",
    "req['Accepted Date'] = pd.to_datetime(req['Accepted Date'])\n",
    "tra['Created At (Transfers)'] = pd.to_datetime(tra['Created At (Transfers)'])\n",
    "negj['effective_date'] = pd.to_datetime(negj['effective_date'])\n",
    "plaid['updated_at'] =  pd.to_datetime(plaid['updated_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids['now'] = datetime.utcnow()\n",
    "req['now'] = datetime.utcnow()\n",
    "tra['now'] = datetime.utcnow()\n",
    "plaid['now'] = datetime.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req['Full Name'] = req['First Name'].astype(str).values + ' ' + req['Last Name'].astype(str).values\n",
    "req = req.drop(['First Name','Last Name'], axis=1)\n",
    "tra['Full Name'] = tra['First Name'].astype(str).values + ' ' + tra['Last Name'].astype(str).values\n",
    "tra = tra.drop(['First Name','Last Name'], axis=1)\n",
    "plaid['Full Name'] = plaid['First Name'].astype(str).values + ' ' + plaid['Last Name'].astype(str).values\n",
    "plaid = plaid.drop(['First Name','Last Name'], axis=1)\n",
    "ids['Full Name'] = ids['First Name'].astype(str).values + ' ' + ids['Last Name'].astype(str).values\n",
    "ids = ids.drop(['First Name','Last Name'], axis=1)\n",
    "bank['Full Name'] = bank['First Name'].astype(str).values + ' ' + bank['Last Name'].astype(str).values\n",
    "bank = bank.drop(['First Name','Last Name'], axis=1)\n",
    "cells['Full Name'] = cells['First Name'].astype(str).values + ' ' + cells['Last Name'].astype(str).values\n",
    "cells = cells.drop(['First Name','Last Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names = ['Lamine Zarrad', 'Kathryn Gruenefeldt', 'George Kurtyka', 'Vicki Apodaca', 'RitaBeth Crague', 'Jenaya Zarrad', 'Heather Lunde']\n",
    "names = []\n",
    "for n in names:\n",
    "    req = req[req['Full Name'] != n]\n",
    "    tra = tra[tra['Full Name'] != n]\n",
    "    plaid = plaid[plaid['Full Name'] != n]\n",
    "    ids = ids[ids['Full Name'] != n]\n",
    "    cells = cells[cells['Full Name'] != n]\n",
    "    bank = bank[bank['Full Name'] != n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra = tra.merge(bank, how='left',left_on='id', right_on='id')\n",
    "tra['dir'] = 0\n",
    "tra['dir'] = (tra['q2_account_id'] == tra['to_account_id'])\n",
    "print(str(len(tra[tra['dir'] == True])) + ' deposits have been made for a total of $' + str(round(sum(tra[tra['dir'] == True]['Amount'].values),2)))\n",
    "print(str(len(tra[tra['dir'] == False])) + ' withdrawls have been made for a total of $' + str(round(sum(tra[tra['dir'] == False]['Amount'].values),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rte = rte.dropna()\n",
    "rte['createddate'] = pd.to_datetime(rte['createddate'])\n",
    "rte['Year'] = rte['createddate'].dt.year\n",
    "rte['Month'] = rte['createddate'].dt.month\n",
    "rte['Day'] = rte['createddate'].dt.day\n",
    "rte['Date'] = rte[\"Year\"].astype(str) + '-' + rte[\"Month\"].astype(str) + '-' + rte[\"Day\"].astype(str)\n",
    "rte['Date'] = pd.to_datetime(rte['Date'])\n",
    "rte.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcids = (rte['customerid'].values)\n",
    "rcodes = (rte['returncode'].values)\n",
    "ramounts = (rte['amount'].values)\n",
    "rdates = (rte['Date'].values)\n",
    "nsfs = pd.DataFrame(rcids, columns=['ids'])\n",
    "nsfs['code'] = rcodes\n",
    "nsfs['amount'] = ramounts\n",
    "nsfs['date'] = rdates\n",
    "nsfs['date'] = pd.to_datetime(nsfs['date'])\n",
    "nsfs['now'] = datetime.now()\n",
    "cptojid = dict(zip(ids['q2_core_pro_customer_id'], ids['id']))\n",
    "nsfs['ids'] =  nsfs['ids'].replace(cptojid)\n",
    "nsfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negj['now'] = datetime.now()\n",
    "negj['time diff'] = (negj['now'] - negj['effective_date']).dt.days\n",
    "negj = negj[negj['time diff'] < 90]\n",
    "siidtojid = dict(zip(ids['segment_intercom_id'], ids['id']))\n",
    "negj['user_id'] =  negj['user_id'].replace(siidtojid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids['timediff'] = (ids['now'] - ids['Created At']).dt.total_seconds() / 3600\n",
    "req['timediff'] = (req['now'] - req['Created At (Payment Requests)']).dt.total_seconds() / 3600\n",
    "tra['timediff'] = (tra['now'] - tra['Created At (Transfers)']).dt.total_seconds() / 3600\n",
    "plaid['timediff'] = (plaid['now'] - plaid['updated_at']).dt.total_seconds() / 3600\n",
    "nsfs['timediff'] = (nsfs['now'] - nsfs['date']).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids2 = ids[ids['timediff'] < (ids['timediff'].max()+1)]\n",
    "#ids2 = ids[ids['timediff'] < (2*24)]\n",
    "ovrfullnames = ids2['id'].unique()\n",
    "ovrfullnames.sort(axis=0)\n",
    "len(ovrfullnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change non ids to ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tatr1 = []\n",
    "tatr1_1 = []\n",
    "tatr2 = []\n",
    "tatr3 = []\n",
    "tatr3_2 = []\n",
    "tatr5 = []\n",
    "tatr6 = []\n",
    "tatr7 = []\n",
    "tatr7_2 = []\n",
    "tatr7_3 = []\n",
    "tatr8 = []\n",
    "tatr10 = []\n",
    "tatr11 = []\n",
    "tatr11_2 = []\n",
    "tatr12 = []\n",
    "tatr12_1 = []\n",
    "tatr12_2 = []\n",
    "tatr12_3 = []\n",
    "tatr12_4 = []\n",
    "tatr13 = []\n",
    "tatr13_2 = []\n",
    "tatr14 = []\n",
    "tatr15 = []\n",
    "tatr16 = []\n",
    "tatr17 = []\n",
    "tatr18 = []\n",
    "tatr19 = []\n",
    "tatr20 = []\n",
    "tatr22 = []\n",
    "tids = []\n",
    "fullnames2 = []\n",
    "segment = []\n",
    "for user in ovrfullnames:\n",
    "    name1 = req[req['id'] == user].sort_values('Created At (Payment Requests)', ascending=True)\n",
    "    name2 = tra[tra['id'] == user].sort_values('Created At (Transfers)', ascending=True)\n",
    "    name3 = plaid[plaid['id'] == user].sort_values('updated_at', ascending=False)\n",
    "    name4 = ids[ids['id'] == user]\n",
    "    name6 = negj[negj['user_id'] == user]\n",
    "    name7 = cells[cells['id'] == user].sort_values('created_at', ascending=False)\n",
    "    atr1 = len(name1[name1['Status'] == 1])\n",
    "    tatr1.append(atr1) \n",
    "    atr1_1 = 0\n",
    "    if (len(name1) > 0):\n",
    "        atr1_1 = len(name1[name1['Status'] == 1])/len(name1)\n",
    "    tatr1_1.append(atr1_1)\n",
    "    name1['time since start'] = name1['Created At (Payment Requests)'] - name1['Created At']\n",
    "    day1t = name1[name1['time since start'] < timedelta(days=1)]\n",
    "    atr2 = len(day1t)\n",
    "    tatr2.append(atr2)\n",
    "    atr3 = name1['Amount (Payment Requests)'].max()\n",
    "    tatr3.append(atr3)\n",
    "    maxinv = 2500\n",
    "    atr3_2 = 0\n",
    "    if (len(name1) > 0):\n",
    "        atr3_2 = len(name1[name1['Amount (Payment Requests)'] > (.95*maxinv)])/len(name1)\n",
    "    tatr3_2.append(atr3_2)\n",
    "    name1mod = name1.copy(deep=True)\n",
    "    name1mod = name1mod[name1mod['Status'] == 1]\n",
    "    name1mod['time diff'] = name1mod['Accepted Date'] - name1mod['Created At (Payment Requests)']\n",
    "    day90 = name1mod[name1mod['time diff'] > timedelta(days=90)]\n",
    "    atr5 = len(day90)\n",
    "    tatr5.append(atr5)\n",
    "    atr6 = len(nsfs[nsfs['ids'] == user])\n",
    "    tatr6.append(atr6)\n",
    "    atr7 = -1\n",
    "    if len(name3) < 1:\n",
    "        atr7 = 0\n",
    "    else:\n",
    "        rawres = name3['Raw Response'].values[0]\n",
    "        obj = json.loads(rawres)\n",
    "        bank = obj[0]['names'][0]\n",
    "        real = name4['Full Name'].values[0]\n",
    "        bank = bank.lower()\n",
    "        real = real.lower()\n",
    "        bank2 = bank.split(' ')\n",
    "        if (bank2[-1] == 'llc'):\n",
    "            atr7 = 0\n",
    "        elif (bank2[-1] == 'jr' or bank2[-1] == 'sr' or bank2[-1] == 'jr.' or bank2[-1] == 'sr.'):\n",
    "            bank = bank2[0] + ' ' + bank2[1]\n",
    "            atr7 = distance.levenshtein(bank,real)\n",
    "        else:\n",
    "            bank = bank2[0] + ' ' + bank2[-1]\n",
    "            atr7 = distance.levenshtein(bank,real)\n",
    "    tatr7.append(atr7)\n",
    "    atr7_2 = -1\n",
    "    if len(name3) < 1:\n",
    "        atr7_2 = 0\n",
    "    else:\n",
    "        atr7_2 = 1\n",
    "    tatr7_2.append(atr7_2)\n",
    "    atr7_3 = atr7 * atr7_2\n",
    "    tatr7_3.append(atr7_3)\n",
    "    atr8 = len(name6[name6['type'] != 'external'])\n",
    "    tatr8.append(atr8)\n",
    "    starttime = name4['Created At'].values[0]\n",
    "    starttime = datetime.utcfromtimestamp(starttime.astype('O')/1e9)\n",
    "    now = datetime.utcnow()\n",
    "    acctage = (now - starttime).days\n",
    "    atr10 = acctage\n",
    "    tatr10.append(atr10)\n",
    "    maxtra = 1500\n",
    "    atr11 = name2[name2['dir'] == True]['Amount'].max()\n",
    "    tatr11.append(atr11)\n",
    "    atr11_2 = name2[name2['dir'] == False]['Amount'].max()\n",
    "    tatr11_2.append(atr11_2)\n",
    "    iden = ids[ids['Full Name'] == (ids[ids['id'] == user]['Full Name'].values[0])]\n",
    "    # rewrite to not base id all off name?\n",
    "    ssnamount = len(iden['ssn'].unique())\n",
    "    tatr12_1.append(ssnamount)\n",
    "    mailamount = len(iden['email'].unique())\n",
    "    tatr12_2.append(mailamount)\n",
    "    phoneamount = len(iden['mobile_phone'].unique())\n",
    "    tatr12_3.append(phoneamount)\n",
    "    dobamount = len(iden['date_of_birth'].unique())\n",
    "    tatr12_4.append(dobamount)\n",
    "    atr12 = max([ssnamount,mailamount,phoneamount]) - 1\n",
    "    tatr12.append(atr12)\n",
    "    atr13 = 'no info'\n",
    "    if(len(name7) > 0):\n",
    "        atr13 = name7['platform'].values[0]\n",
    "    tatr13.append(atr13)\n",
    "    atr13_2 = len(name7['signature'].unique())\n",
    "    tatr13_2.append(atr13_2)\n",
    "    sigs = name7['signature'].unique()\n",
    "    totsigs = 0\n",
    "    for k in sigs:\n",
    "        totsigs = totsigs + len(cells[cells['signature'] == k])\n",
    "    atr14 = totsigs - atr13_2\n",
    "    tatr14.append(atr14)\n",
    "    urls = name4.dropna(subset=['business_url'])\n",
    "    loc = name4['country'].unique()\n",
    "    atr15 = (loc[0] == 'US')\n",
    "    tatr15.append(atr15)\n",
    "    atr16 = len(name6[name6['type'] == 'external'])\n",
    "    tatr16.append(atr16)\n",
    "    atr17 = len(urls)>0\n",
    "    tatr17.append(atr17)\n",
    "    atr18 = name4['industry'].values[0]\n",
    "    tatr18.append(atr18)\n",
    "    atr19 = name4['occupation'].values[0]\n",
    "    tatr19.append(atr19)\n",
    "    name = name4['Full Name'].values[0]\n",
    "    segid = name4['segment_intercom_id'].values[0]\n",
    "    caps = sum(1 for c in name if c.isupper())\n",
    "    atr20 = 1\n",
    "    if (len(name.replace(\" \", \"\")) != 0):\n",
    "        atr20 = caps/len(name.replace(\" \", \"\"))\n",
    "    tatr20.append(atr20)\n",
    "    atr22 = name4['expected_yearly_income_id'].values[0]\n",
    "    tatr22.append(atr22)\n",
    "    tid = user\n",
    "    tids.append(tid)\n",
    "    fullnames2.append(name)\n",
    "    segment.append(segid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(fullnames2, columns=['Name'])\n",
    "final['Successful Invoices'] = tatr1\n",
    "final['Invoice Pct'] = tatr1_1\n",
    "final['First 24 Hour'] = tatr2\n",
    "final['Big Invoice Pct'] = tatr3_2\n",
    "final['Overdue Invoices'] = tatr5\n",
    "final['NSF count'] = tatr6\n",
    "final['Linked Acct'] = tatr7_2\n",
    "final['Linked Name'] = tatr7\n",
    "final['Linked Transfer'] = tatr7_3\n",
    "final['Negative Joust'] = tatr8\n",
    "final['Acct Age'] = tatr10\n",
    "final['Biggest Deposit'] = tatr11\n",
    "final = final.fillna(0)\n",
    "final['Attempts'] = tatr12\n",
    "#final['Phone os'] = tatr13\n",
    "final['Mult Phones'] = tatr13_2\n",
    "final['Repeat Phone'] = tatr14\n",
    "final['Domestic'] = tatr15\n",
    "final['Negative External'] = tatr16\n",
    "final['Website'] = tatr17\n",
    "final = final.fillna(0)\n",
    "final['Industry'] = tatr18\n",
    "final = final.fillna('Other')\n",
    "#final['Job'] = tatr19\n",
    "final['Capitals'] = tatr20\n",
    "final['Income'] = tatr22\n",
    "final['id'] = tids\n",
    "final = final.fillna(0)\n",
    "final['segment'] = segment\n",
    "final = final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.set_index('Name')\n",
    "final = final.replace(True, 1)\n",
    "final = final.replace(False, 0)\n",
    "ind_dict = {'Web Mobile & Software Dev':4, 'IT & Networking':4, 'Data Science & Analytics':6, 'Engineering & Architecture':6, 'Design & Creative':3, 'Translation':6, 'Legal':8, 'Admin Support':7, 'Sales & Marketing':4, 'Customer Service':7, 'Accounting & Consulting':8, 'Other':3}\n",
    "final = final.replace({'Industry': ind_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['Successful Invoices'] > 5, 'Successful Invoices'] = 6\n",
    "risk = .1\n",
    "vals = np.array(final['Successful Invoices'].values)\n",
    "best = 6\n",
    "worst = 0\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Successful Invoices'] = edit\n",
    "final['Successful Invoices'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['Invoice Pct'] > .8, 'Invoice Pct'] = .8\n",
    "risk = .25\n",
    "vals = np.array(final['Invoice Pct'].values)\n",
    "best = .8\n",
    "worst = 0\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Invoice Pct'] = edit\n",
    "final['Invoice Pct'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['First 24 Hour'] > 3, 'First 24 Hour'] = 3\n",
    "final.loc[final['First 24 Hour'] < 1, 'First 24 Hour'] = 1\n",
    "risk = .5\n",
    "vals = np.array(final['First 24 Hour'].values)\n",
    "best = 1\n",
    "worst = 3\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['First 24 Hour'] = edit\n",
    "final['First 24 Hour'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = .25\n",
    "vals = np.array(final['Big Invoice Pct'].values)\n",
    "best = 0\n",
    "worst = 1\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Big Invoice Pct'] = edit\n",
    "final['Big Invoice Pct'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['Overdue Invoices'] > 4, 'Overdue Invoices'] = 4\n",
    "risk = 1.25\n",
    "vals = np.array(final['Overdue Invoices'].values)\n",
    "best = 0\n",
    "worst = 4\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Overdue Invoices'] = edit\n",
    "final['Overdue Invoices'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['NSF count'] > 3, 'NSF count'] = 3\n",
    "risk = 1.75\n",
    "vals = np.array(final['NSF count'].values)\n",
    "best = 0\n",
    "worst = 3\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['NSF count'] = edit\n",
    "final['NSF count'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = 1\n",
    "vals = np.array(final['Linked Acct'].values)\n",
    "best = 1\n",
    "worst = 0\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Linked Acct'] = edit\n",
    "final['Linked Acct'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['Linked Name'] > 0, 'Linked Name'] = 1\n",
    "risk = 1.75\n",
    "vals = np.array(final['Linked Name'].values)\n",
    "best = 1\n",
    "worst = 0\n",
    "edit = 100 - (100 * ((((vals - worst)/(best - worst))**risk)))\n",
    "final['Linked Name'] = edit\n",
    "final['Linked Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['Linked Transfer'] > 0, 'Linked Transfer'] = 2\n",
    "risk = 2\n",
    "vals = np.array(final['Linked Transfer'].values)\n",
    "best = 2\n",
    "worst = 0\n",
    "edit = 100 - (100 * ((((vals - worst)/(best - worst))**risk)))\n",
    "final['Linked Transfer'] = edit\n",
    "final['Linked Transfer'].unique()\n",
    "# edit logic to account for plaid no info as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['Negative Joust'] > 0, 'Negative Joust'] = 1\n",
    "risk = 2\n",
    "vals = np.array(final['Negative Joust'].values)\n",
    "best = 0\n",
    "worst = 1\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Negative Joust'] = edit\n",
    "final['Negative Joust'].unique()\n",
    "# change exists to 0-50 balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['Acct Age'] > 60, 'Acct Age'] = 60\n",
    "risk = .75\n",
    "vals = np.array(final['Acct Age'].values)\n",
    "best = 60\n",
    "worst = 0\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Acct Age'] = edit\n",
    "final['Acct Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['Biggest Deposit'] < 1425, 'Biggest Deposit'] = 1425\n",
    "final.loc[final['Biggest Deposit'] > 1500, 'Biggest Deposit'] = 1500\n",
    "risk = 1\n",
    "vals = np.array(final['Biggest Deposit'].values)\n",
    "best = 1425\n",
    "worst = 1500\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Biggest Deposit'] = edit\n",
    "final['Biggest Deposit'].unique()\n",
    "# 1425 is .95*1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['Attempts'] > 2, 'Attempts'] = 2\n",
    "risk = 1.25\n",
    "vals = np.array(final['Attempts'].values)\n",
    "best = 0\n",
    "worst = 2\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Attempts'] = edit\n",
    "final['Attempts'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['Mult Phones'] = final['Mult Phones'] - 1\n",
    "final.loc[final['Mult Phones'] < 0, 'Mult Phones'] = 0\n",
    "final.loc[final['Mult Phones'] > 2, 'Mult Phones'] = 2\n",
    "risk = 1.5\n",
    "vals = np.array(final['Mult Phones'].values)\n",
    "best = 0\n",
    "worst = 2\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Mult Phones'] = edit\n",
    "final['Mult Phones'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['Repeat Phone'] > 1, 'Repeat Phone'] = 1\n",
    "risk = 1.25\n",
    "vals = np.array(final['Repeat Phone'].values)\n",
    "best = 0\n",
    "worst = 1\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Repeat Phone'] = edit\n",
    "final['Repeat Phone'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = 2\n",
    "vals = np.array(final['Domestic'].values)\n",
    "best = 1\n",
    "worst = 0\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Domestic'] = edit\n",
    "final['Domestic'].unique()\n",
    "# change exists to .5 for na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['Negative External'] > 2, 'Negative External'] = 2\n",
    "risk = 2\n",
    "vals = np.array(final['Negative External'].values)\n",
    "best = 0\n",
    "worst = 2\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Negative External'] = edit\n",
    "final['Negative External'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = 1\n",
    "vals = np.array(final['Website'].values)\n",
    "best = 1\n",
    "worst = 0\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Website'] = edit\n",
    "final['Website'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = .5\n",
    "vals = np.array(final['Industry'].values)\n",
    "best = 10\n",
    "worst = 0\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Industry'] = edit\n",
    "final['Industry'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final['Capitals'] < 1, 'Capitals'] = 0\n",
    "risk = .75\n",
    "vals = np.array(final['Capitals'].values)\n",
    "best = 0\n",
    "worst = 1\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Capitals'] = edit\n",
    "final['Capitals'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = .1\n",
    "vals = np.array(final['Income'].values)\n",
    "best = 5\n",
    "worst = 0\n",
    "edit = 100 * ((((vals - worst)/(best - worst))**risk))\n",
    "final['Income'] = edit\n",
    "final['Income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# throw in some socure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setweights = [75, 100, 25, 50, 75, 100, 50, 100, 100, 100, 75, 75, 50, 75, 100, 100, 100, 25, 75, 100, 75]\n",
    "cols = final.columns.values\n",
    "setweights = np.array(setweights) / sum(setweights)\n",
    "final['joust_score'] = 0\n",
    "for k in range(len(setweights)):\n",
    "    final['joust_score'] = final['joust_score'].values + (setweights[k] * final[cols[k]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si = final['joust_score'].values\n",
    "#succs = np.interp(si, (49.230769230769226, 100), (0, 100))\n",
    "#final['joust_score'] = succs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin2 = final.sort_values('id', ascending=True)\n",
    "fin2['Fname'] = fin2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = fin2.head().to_dict('records')[0]\n",
    "type({k: mydict[k] for k in list(mydict)[:-4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total2 = status[status['archived'] == False]\n",
    "total2 = total2[total2['status'] == 2]\n",
    "total2 = total2[total2['q2_core_pro_verification_status'] == 'verified']\n",
    "total2.drop_duplicates(subset =\"id\", inplace = True)\n",
    "total2 = total2.sort_values(by='id', ascending = True)\n",
    "cleans = total2['id'].values\n",
    "fin2 = fin2[fin2['id'].isin(cleans)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in fin2.to_dict('records'):\n",
    "    analytics.track(k['segment'], 'update account holder score' ,{\n",
    "        'attributes': {n: k[n] for n in list(k)[:-4]},\n",
    "        'type': 'account_holder', \n",
    "        'id': k['id'],\n",
    "        'joust_score': k['joust_score'],\n",
    "        'segment': k['segment']\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
